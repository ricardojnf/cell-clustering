Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. In case of doubt, you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.
- You can include references to images or html files such as the reports generated with clusters. To do this, simply include this document in the folder with the reports or images and refer them in the text by the file name in an isolated line. For example, the line

test.png

refers to a test.png image file in the same folder as this document.

QUESTIONS:

Q1: Explain how you selected the best attributes for the clustering phase. In particular, indicate the visualization methods used to explore the extracted attributes and any statistical tests used.

R1: After extracting the 18 features (6 from each of the extraction methods - PCA, t-SNE, Isomap) we used the SelectKBest method, in order to select the 6 features with the most value in the f_classif. In choosing clustering combinations, we decided to use a for between 2 and 5 features that, with SelectKBest, selected the k-th best. We also decided to use some visualization methods (such as ScatterMatrix, ParallelCoordinates and RadViz) for the 6 selected features, from which we removed a combination of 3 features chosen by us. The images of the visualization methods can be found in the 

DataVisualization 

folder.

Q2: After selecting the attributes, did you standardize or normalize the values? Justify your decision.

R2: We decided to standardize, since, since the features were extracted from 3 different methods, the orders of magnitude are different, so the best decision is to standardize so they can be comparable.


Q3: Explain how you found the neighborhood radius value (epsilon) for the DBSCAN algorithm by following the procedure described in the article "A density-based algorithm for discovering clusters in large spatial databases with noise".

R3: To calculate the distances between points, we used the K-NN Classifier. As this classifier has a default value of 5 neighbors, we used this value instead of the value of 4 neighbors as recommended in the article. Then, as described in the article, we plotted the distances from the 5th nearest neighbor to each point. The value we chose for epsilon is the lowest value on the elbow of the plot, and we introduced a gap range to be able to analyze which is the best in this range using the various metrics for evaluating the clusters.


Q4: Examining the clusters generated by the DBSCAN algorithm with the value optimized by the method described in the article, do you think the result is adequate to cluster these images? Justify your answer.

R4: DBSCAN is a very good method for clustering when groups of points are visually separable. In this specific case, where the boundaries between the various types of images are not very explicit, this method does not have an exceptional result, as it is not very clear where each group begins and ends. Since the classification always depends on the distance expressed by epsilon, the algorithm can classify as noise, points that are not even outliers, but that may be a little further than epsilon.


Q5: Describe your analysis of the k (for K-Means) and epsilon (for DBSCAN) parameters using the internal and external indicators referred in the assignment page. Include the two plots of the indicator values â€‹â€‹(indicating the image name of each plot in one line in your answer) as a function of the k and epsilon parameters and explain how you chose the ranges for examining these parameters. Indicate, with justification, what conclusions you can draw from this analysis.

R5: In order to help biologists to better describe the various images, we opted to privilege the precision, so that the images in each cluster were as close as possible to belonging to the same family, and therefore, the combinations we chose were those with the best precision values. For KMeans, the best result was for the combination we chose and the metrics plot can be found at

ClusteringAnalysis/KMeans_3our_comb.png

The best solution, is in html

test_kmeans.html

and for DBSCAN, the best result was for the combination given by SelectKBest for 3 features and the metrics plot can be found at

ClusteringAnalysis/DBSCAN_3feats.png

The best solution, is in html

test_db.html

Regarding the chosen value ranges, for KMeans, we analyzed the best combinations between 2 and 5 features (using SelectKBest) and a feature combination chosen by us through visualization methods and for each combination, we tested between 2 to 10 clusters. The pair of values chosen was the one with the highest precision value. For DBSCAN, we analyzed the best combinations between 2 and 5 features (using SelectKBest) and a feature combination chosen by us through visualization methods and for each combination, we plotted the distances to find the epsilon value, testing later for a range of that value, choosing the pair of attributes that presented the highest precision value.
Through the metrics we can conclude that from certain values, clusters tend to stagnate and not improve much more (or even get worse).

Q6: Select some of the parameter values â€‹â€‹tested in question five and examine the corresponding clusters more closely, generating the HTML file with the images. Explain how you selected these parameter values, discuss the different options and propose a recommendation that could help the biologists' task of classifying cells and rejecting segmentation errors.

R6: As explained earlier about parameter selection, for KMeans, we analyzed the best combinations between 2 and 5 features (using SelectKBest) and a feature combination chosen by us through visualization methods and for each combination, we tested between 2 to 10 clusters. The pair of values chosen was the one with the highest precision value. For DBSCAN, we analyzed the best combinations between 2 and 5 features (using SelectKBest) and a feature combination chosen by us through visualization methods and for each combination, we plotted the distances to find the epsilon value, testing later for a range of that value, choosing the pair of attributes that presented the highest precision value.
For biologists, they can choose a solution that presents greater precision in predictions by making clusters in which the images are very identical, or they can choose larger clusters that group a greater diversity of images that may look similar but may happen that are not the same family.

Q7: Discuss advantages or problems with these two algorithms (K-Means and DBSCAN) for the purpose of helping biologists to organize these images, considering your theoretical knowledge of these algorithms as well as the results you obtained in your work.

R7: An advantage of K-Means is that there is a good definition of the boundaries between the clusters (since the categorization of the cluster is given by the central point of each cluster and the distance between these centroids) and a disadvantage is that it only allows to find linearly separable clusters . On the other hand, DBSCAN has the advantage of allowing non-linearly separable clusters to be found, but as the classification is made by the distance given by the epsilon value, the definition of borders is not very good and can classify as noise, points that could be part of that cluster.

Q8: Consider other clustering algorithms embedded in the Scikit-Learn library. Choose one and apply it to this problem, optimizing the parameters you deem appropriate in the way that you find adequate. Justify your choices and discuss whether this option would yield more useful results for biologists.

R8: We decided to use Agglomerative clustering. As they are grouped in a hierarchy, this algorithm is grouped successively into groups whose points are similar, which can be useful for biologists to have very specific groups that can help to identify phases and transitions between phases. For the algorithm parameters, we left the linkage as ward as it minimized the variance within the clusters and consequently the affinity as euclidean and then, as in kmeans, we analyzed the best combinations between 2 and 5 features (using SelectKBest) and a feature combination chosen by us through visualization methods and for each combination, we tested between 2 to 10 clusters. The pair of values chosen was the one with the highest precision value. 
The best result was for the combination we chose and the metrics plot can be found at

ClusteringAnalysis/Agglomerative_3feats_ourComb.png

The best solution, is in html

test_agg.html

Q9: (Optional) Implement the Bissecting K-Means hierarchical clustering algorithm as described in the assignment page and Lecture 19. Examine and discuss the results and their application to the problem of helping the biologists select and classify cell images.

R9: When implementing Bissecting KMeans, we applied the same idea as the others and selected the best combination of features and number of clusters with the result from the metrics (we stop Bissect KMeans when the specified number of clusters reaches). When viewing the results given by Bissecting KMeans, the fact that it always separates the largest cluster, it is possible to see similarities between clusters of the same level and that differ only slightly between them. This can be useful in helping biologists to differentiate more specifically where the differences are not so explicit. Some examples of the metrics can be seen in the ClusteringAnalysis folder in the images that say BissectingKMeans. The best solution, whose cluster is in html

test_bisK.html

corresponds to the combination of features [1,2,6,12,13] and 10 clusters.

